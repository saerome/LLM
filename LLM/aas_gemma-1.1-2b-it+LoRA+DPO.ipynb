{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d6168d",
   "metadata": {},
   "source": [
    "# Preference Fine-Tuning with DPO "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c6759e",
   "metadata": {},
   "source": [
    "사전학습된 LLM 기반으로 DPO(Direct Preference Optimization) 방법을 통해 Preference 파인튜닝하는 방법에 대해 살펴보겠습니다.  \n",
    "DPO 파인튜닝은 간단하게 두 단계로 이루어지는데,  \n",
    "1. **Preference Dataset** 준비 (**Prompt**에 대한 **Positive**, **Negative** Generation 쌍으로 구성)  \n",
    "2. **DPO 최적화**: DPO Loss의 Log-likelihood 값을 최대화하는 방향으로 학습  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d6a8c9",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60f05a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Suwon 설정 필요\n",
    "import os\n",
    "\n",
    "os.environ['REQUESTS_CA_BUNDLE'] = '/etc/ssl/certs/ca-certificates.crt'\n",
    "os.environ['HTTP_PROXY'] ='http://75.17.107.42:8080'\n",
    "os.environ['HTTPS_PROXY'] ='http://75.17.107.42:8080'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68a39677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Suwon 설정 필요\n",
    "import ssl\n",
    "\n",
    "if hasattr(ssl, '_create_unverified_context'):\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca60a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f855e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q --user transformers==4.38.2\n",
    "# !pip install -q --user datasets==2.18.0\n",
    "# !pip install -q --user peft==0.9.0\n",
    "# !pip install -q --user trl==0.7.11\n",
    "# !pip install -q --user accelerate==0.27.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "715eb288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, pipeline\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import DPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5e51b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 22 14:55:37 2024       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: 11.6     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P40           Off  | 00000000:04:00.0 Off |                  Off |\r\n",
      "| N/A   43C    P0    57W / 250W |     10MiB / 24451MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e8f9d6",
   "metadata": {},
   "source": [
    "## 1. Dataset: Preference Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f7c288",
   "metadata": {},
   "source": [
    "파인튜닝을 위한 Preference Dataset으로는 Open Dataset \"jondurbin/truthy-dpo-v0.1\"를 사용하겠습니다.\n",
    "이 데이터셋은  LLM의 Truthfulness를 향상시키기 위한 목적으로 작성된 1,016개 데이터를 가지고 있으며,\n",
    "**'prompt', 'chosen', 'rejected'** 쌍으로 구성되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35359c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_dataset(\"jondurbin/truthy-dpo-v0.1\")\n",
    "dataset = load_dataset(\"/group-volume/sr_edu/AI-Application-Specialist/LLM/dataset/truthy-dpo-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7716127a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'source', 'system', 'prompt', 'chosen', 'rejected'],\n",
       "        num_rows: 1016\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c87bc89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '6afd3f3e1254321c2c55687fecc55d07',\n",
       " 'source': 'truthy_dpo',\n",
       " 'system': 'You are an unbiased, uncensored, helpful assistant.',\n",
       " 'prompt': 'Do all Muslim women wear burqas as their religious clothing?',\n",
       " 'chosen': 'No, not all Muslim women wear burqas. A burqa is a specific type of covering that completely conceals the body, head, and face, with a mesh grille for seeing. Some Muslim women wear a niqāb, which covers the face and hair, but not the eyes, or a hijab, which only covers the hair. Many Muslim women do not wear any face or head coverings at all. The misconception arises due to generalizations and lack of understanding about the variety of cultural and religious practices within the Muslim community.',\n",
       " 'rejected': 'No, not all Muslim women wear burqas. Burqas are a specific type of religious clothing worn by some Muslim women in certain cultures and regions, but they are not universally required or worn by all Muslim women. Other types of religious clothing for Muslim women include hijabs, niqabs, and abayas.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5de1f8a",
   "metadata": {},
   "source": [
    "데이터셋은 Gemma LLM 파인튜닝을 위한 적절한 Chat Template으로 변환합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb33e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(example):\n",
    "    prompt = example['prompt']\n",
    "    rejected = example['rejected']\n",
    "    chosen = example['chosen']\n",
    "\n",
    "    example['prompt'] = f\"<bos><start_of_turn>system\\n <end_of_turn><start_of_turn>user\\n{prompt}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "    example['rejected'] = f\"{rejected}<end_of_turn>\\n<eos>\"\n",
    "    example['chosen'] = f\"{chosen}<end_of_turn>\\n<eos>\"\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f409502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = dataset.map(generate_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6525f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '04c275bf738fd391b7fe25e25fe7bed3',\n",
       " 'source': 'truthy_dpo',\n",
       " 'system': 'You are an unbiased, uncensored, helpful assistant.',\n",
       " 'prompt': \"<bos><start_of_turn>system\\n <end_of_turn><start_of_turn>user\\nWhat's the nearest national park to you?<end_of_turn>\\n<start_of_turn>model\\n\",\n",
       " 'chosen': \"As an AI, I don't have a physical location, so I can't provide the distance to the nearest national park.<end_of_turn>\\n<eos>\",\n",
       " 'rejected': \"I don't have access to the user's location, so I can't determine the nearest national park.<end_of_turn>\\n<eos>\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "544db7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = transformed_dataset['train'].train_test_split(test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfe7e70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'source', 'system', 'prompt', 'chosen', 'rejected'],\n",
       "        num_rows: 965\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'source', 'system', 'prompt', 'chosen', 'rejected'],\n",
       "        num_rows: 51\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036b2b63",
   "metadata": {},
   "source": [
    "## 2. Foundation Model: gemma-1.1-2b-it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53ff3bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dccea4",
   "metadata": {},
   "source": [
    "파인튜닝을 위해 사용할 Foundation Model은 Google의 gemma-1.1-2b-it 모델입니다.  \n",
    "\n",
    "(https://huggingface.co/google/gemma-1.1-2b-it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc7b1377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee2d8f6c6f84d24ab00583aaa94e687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_ckpt = \"google/gemma-1.1-2b-it\"\n",
    "model_ckpt = \"/group-volume/sr_edu/AI-Application-Specialist/LLM/model/gemma-1.1-2b-it\"\n",
    "\n",
    "# [실습] 다음 코드를 완성하세요!! \n",
    "# 사전 학습된 'google/gemma-1.1-2b-it' 모델과 토크나이저를 가져옵니다.\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_ckpt,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float32,\n",
    "    # revision=\"float16\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c90cbb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special Tokens: {'bos_token': '<bos>', 'eos_token': '<eos>', 'unk_token': '<unk>', 'pad_token': '<eos>', 'additional_special_tokens': ['<start_of_turn>', '<end_of_turn>']}\n"
     ]
    }
   ],
   "source": [
    "print(\"Special Tokens:\", tokenizer.special_tokens_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b4cc0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What's the nearest national park to you?\"\n",
    "\n",
    "prompt = f\"\"\"<bos><start_of_turn>system\n",
    "You are a helpful AI assistant.<end_of_turn>\n",
    "<start_of_turn>user\n",
    "{question}<end_of_turn>\n",
    "<start_of_turn>model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88dfdda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><start_of_turn>system\n",
      "You are a helpful AI assistant.<end_of_turn>\n",
      "<start_of_turn>user\n",
      "What's the nearest national park to you?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "I do not have personal geographic information or the ability to access location data, so I am unable to provide information regarding the nearest national parks to me. For current information on national parks near your location, please check official government websites such as the National Park Service website.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=256)\n",
    "\n",
    "outputs = pipe(\n",
    "    prompt,\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.2,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639de269",
   "metadata": {},
   "source": [
    "## 3. Align LLM with TRL and the DPOTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8f4069",
   "metadata": {},
   "source": [
    "효율적인 DPO Training을 위해 PEFT LoRA, Training Arguments, DPO Trainer를 차례로 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "277e4a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [실습] 다음 코드를 완성하세요!! \n",
    "# PEFT LoRA 학습을 위한 Config를 설정합니다. (r, lora_alpha, lora_dropout, bias, target_modules, task_type)\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    # target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6031076",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e9329a",
   "metadata": {},
   "source": [
    "DPO 학습을 위한 TrainingArguments와 DPO Trainer를 정의합니다. \n",
    "DPO 관련 중요한 파라미터는 \"**beta**\" 값으로 일반적으로 0.1 ~ 0.5 범위입니다.  \n",
    "Beta 값이 작을수록 레퍼런스 모델과의 차이가 커질 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba1732dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./dpo_results\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    do_eval=True,\n",
    "    optim=\"adamw_hf\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    logging_steps=100,\n",
    "    max_steps=200,\n",
    "    # logging_dir=\"/tensorboard\",\n",
    "    learning_rate=2e-4,\n",
    "    eval_steps=50,\n",
    "    num_train_epochs=1,\n",
    "    save_steps=500,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    dataloader_num_workers=4,\n",
    "    dataloader_prefetch_factor=2,\n",
    "    fp16=True,\n",
    "    remove_unused_columns=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cdb51b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f33ed4aa4046719b5821d9610cb021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/965 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d693646b410a4ec9b9596b7982d647e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# [실습] 다음 코드를 완성하세요!! \n",
    "# DPO 학습을 위한 Trainer를 설정합니다. (model, ref_model, args, train_dataset, eval_dataset, tokenizer, peft_config, etc.)\n",
    "dpo_trainer = DPOTrainer(\n",
    "    model,\n",
    "    ref_model=None,\n",
    "    args=training_args,\n",
    "    beta=0.1,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    max_prompt_length=512,\n",
    "    max_length=1024,\n",
    "    peft_config=lora_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2aeacc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7513278a",
   "metadata": {},
   "source": [
    "전체 파라미터의 약 0.07% 만을 DPO Fine-Tuning 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f48d302f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1843200 || all params: 2508015616 || trainable%: 0.073492365368111\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620ab0ba",
   "metadata": {},
   "source": [
    "메모리 리소스 제약으로 실습에서는 200 스텝만 진행합니다. 학습은 약 3분 정도 소요됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c080802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 04:55, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.214911</td>\n",
       "      <td>2.729933</td>\n",
       "      <td>0.230389</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>2.499544</td>\n",
       "      <td>-278.840637</td>\n",
       "      <td>-240.484177</td>\n",
       "      <td>-19.279718</td>\n",
       "      <td>-19.640738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.353700</td>\n",
       "      <td>0.231043</td>\n",
       "      <td>0.068711</td>\n",
       "      <td>-7.751345</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>7.820055</td>\n",
       "      <td>-358.657959</td>\n",
       "      <td>-267.096405</td>\n",
       "      <td>-18.395983</td>\n",
       "      <td>-18.818966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.353700</td>\n",
       "      <td>0.114746</td>\n",
       "      <td>0.833262</td>\n",
       "      <td>-8.037666</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>8.870929</td>\n",
       "      <td>-361.521179</td>\n",
       "      <td>-259.450897</td>\n",
       "      <td>-18.548679</td>\n",
       "      <td>-19.207865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.146200</td>\n",
       "      <td>0.092227</td>\n",
       "      <td>1.090639</td>\n",
       "      <td>-7.870296</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>8.960935</td>\n",
       "      <td>-359.847504</td>\n",
       "      <td>-256.877136</td>\n",
       "      <td>-18.664705</td>\n",
       "      <td>-19.382290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=0.24990934371948242, metrics={'train_runtime': 297.0492, 'train_samples_per_second': 0.673, 'train_steps_per_second': 0.673, 'total_flos': 0.0, 'train_loss': 0.24990934371948242, 'epoch': 0.21})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435286bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# save DPO adapter model\n",
    "ADAPTER_MODEL = \"dpo_adapter\"\n",
    "\n",
    "trainer.model.save_pretrained(ADAPTER_MODEL)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373cea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# free the memory\n",
    "del model\n",
    "del trainer\n",
    "torch.cuda.empty_cache()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a42e37",
   "metadata": {},
   "source": [
    "## 4. Fine-tuned LLM Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead3981b",
   "metadata": {},
   "source": [
    "DPO 기반 파인튜닝된 모델을 테스트해 보도록 하겠습니다.  \n",
    "Gemma-1.1-2b-it 모델은 이미 Instruction, Preference 학습이 충분히 되어 있는 모델인 관계로, \n",
    "DPO 학습에 의한 변화를 체감하기 어려울 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce051849",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BASE_MODEL = \"google/gemma-1.1-2b-it\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, device_map='auto', torch_dtype=torch.float32)\n",
    "# model = PeftModel.from_pretrained(model, ADAPTER_MODEL, device_map='auto', torch_dtype=torch.float32)\n",
    "model.load_adapter(ADAPTER_MODEL)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7cad5779",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What's the nearest national park to you?\"\n",
    "\n",
    "prompt = f\"\"\"<bos><start_of_turn>system\n",
    "You are a helpful AI assistant.<end_of_turn>\n",
    "<start_of_turn>user\n",
    "{question}<end_of_turn>\n",
    "<start_of_turn>model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2b84ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am unable to express personal or location-based information as I am an artificial intelligence and do not have personal experiences or physical presence.\n"
     ]
    }
   ],
   "source": [
    "pipe_finetuned = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=256)\n",
    "\n",
    "outputs = pipe_finetuned(\n",
    "    prompt,\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.2,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d08ef6",
   "metadata": {},
   "source": [
    "- Ref. Rafailov et al., \"Direct Preference Optimization: Your Language Model is Secretly a Reward Model\", 2023, Stanford University"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
